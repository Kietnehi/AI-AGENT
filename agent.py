"""Main AI Agent with Gemini LLM"""
import os
import sys
from google import genai
from typing import Dict, List, Optional
from config import Config
from tools import search_web, wolfram_compute, DataAnalysisTool


class AIAgent:
    """AI Agent with Gemini LLM and multiple tools"""
    
    def __init__(self):
        """Initialize AI Agent"""
        # Validate configuration
        Config.validate()
        
        # Initialize Gemini client
        os.environ['GEMINI_API_KEY'] = Config.GEMINI_API_KEY
        self.client = genai.Client()
        self.model_name = 'gemini-2.5-flash'
        self.chat_history = []
        
        # Initialize tools
        self.data_tool = DataAnalysisTool()
        
        # Conversation history
        self.history = []
        
        print("ü§ñ AI Agent ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o!")
        print(f"üì° C√¥ng c·ª• t√¨m ki·∫øm: {Config.get_search_engine_display()}")
        print(f"üßÆ Wolfram Alpha: {'‚úì' if Config.WOLFRAM_APP_ID else '‚úó'}")
        print()
    
    def start_conversation(self):
        """Start a new conversation"""
        self.chat_history = []
        self.history = []
    
    def _build_system_prompt(self) -> str:
        """Build system prompt with available tools"""
        prompt = """B·∫°n l√† m·ªôt AI Agent th√¥ng minh v·ªõi nhi·ªÅu kh·∫£ nƒÉng:

1. T√åM KI·∫æM WEB: B·∫°n c√≥ th·ªÉ t√¨m ki·∫øm th√¥ng tin tr√™n internet b·∫±ng c√°ch s·ª≠ d·ª•ng l·ªánh:
   [SEARCH: <truy v·∫•n t√¨m ki·∫øm>]
   
2. T√çNH TO√ÅN TO√ÅN H·ªåC: B·∫°n c√≥ th·ªÉ th·ª±c hi·ªán t√≠nh to√°n ph·ª©c t·∫°p v·ªõi Wolfram Alpha:
   [WOLFRAM: <ph√©p t√≠nh ho·∫∑c c√¢u h·ªèi to√°n h·ªçc>]
   
3. PH√ÇN T√çCH D·ªÆ LI·ªÜU CSV: B·∫°n c√≥ th·ªÉ ph√¢n t√≠ch file CSV v√† t·∫°o bi·ªÉu ƒë·ªì:
   - [LOAD_CSV: <ƒë∆∞·ªùng d·∫´n file>] - T·∫£i file CSV
   - [CSV_INFO] - Xem th√¥ng tin chi ti·∫øt
   - [CSV_ANALYZE: <t√™n c·ªôt>] - Ph√¢n t√≠ch c·ªôt c·ª• th·ªÉ
   - [CREATE_CHART: type=<lo·∫°i>, x=<c·ªôt x>, y=<c·ªôt y>, title=<ti√™u ƒë·ªÅ>] - T·∫°o bi·ªÉu ƒë·ªì
     C√°c lo·∫°i bi·ªÉu ƒë·ªì: bar, line, scatter, histogram, pie, box, heatmap

Khi ng∆∞·ªùi d√πng y√™u c·∫ßu th√¥ng tin ho·∫∑c t√≠nh to√°n, h√£y s·ª≠ d·ª•ng c√°c c√¥ng c·ª• tr√™n.
Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát m·ªôt c√°ch th√¢n thi·ªán v√† chuy√™n nghi·ªáp.
"""
        return prompt
    
    def _parse_and_execute_commands(self, text: str) -> str:
        """Parse and execute commands in the response"""
        result = text
        
        # Search command
        if "[SEARCH:" in text:
            start = text.find("[SEARCH:")
            end = text.find("]", start)
            if end != -1:
                query = text[start+8:end].strip()
                search_result = search_web(query)
                result = text[:start] + f"\n\n{search_result}\n\n" + text[end+1:]
        
        # Wolfram command
        if "[WOLFRAM:" in text:
            start = text.find("[WOLFRAM:")
            end = text.find("]", start)
            if end != -1:
                query = text[start+9:end].strip()
                wolfram_result = wolfram_compute(query)
                
                # Format result based on type
                if isinstance(wolfram_result, dict):
                    formatted_result = ""
                    if wolfram_result.get('text_results'):
                        formatted_result += "\n".join(wolfram_result['text_results'])
                    if wolfram_result.get('plots'):
                        formatted_result += f"\n\nüìä C√≥ {len(wolfram_result['plots'])} bi·ªÉu ƒë·ªì ƒë∆∞·ª£c t·∫°o"
                    if wolfram_result.get('images'):
                        formatted_result += f"\n\nüñºÔ∏è C√≥ {len(wolfram_result['images'])} h√¨nh ·∫£nh ƒë∆∞·ª£c t·∫°o"
                else:
                    formatted_result = str(wolfram_result)
                
                result = text[:start] + f"\n\nüßÆ K·∫øt qu·∫£ t√≠nh to√°n:\n{formatted_result}\n\n" + text[end+1:]
        
        # CSV commands
        if "[LOAD_CSV:" in text:
            start = text.find("[LOAD_CSV:")
            end = text.find("]", start)
            if end != -1:
                file_path = text[start+10:end].strip()
                csv_result = self.data_tool.load_csv(file_path)
                result = text[:start] + f"\n\n{csv_result}\n\n" + text[end+1:]
        
        if "[CSV_INFO]" in text:
            csv_result = self.data_tool.get_info()
            result = result.replace("[CSV_INFO]", f"\n\n{csv_result}\n\n")
        
        if "[CSV_ANALYZE:" in text:
            start = text.find("[CSV_ANALYZE:")
            end = text.find("]", start)
            if end != -1:
                column = text[start+13:end].strip()
                csv_result = self.data_tool.analyze_column(column)
                result = text[:start] + f"\n\n{csv_result}\n\n" + text[end+1:]
        
        if "[CREATE_CHART:" in text:
            start = text.find("[CREATE_CHART:")
            end = text.find("]", start)
            if end != -1:
                params_str = text[start+14:end].strip()
                params = {}
                for param in params_str.split(","):
                    if "=" in param:
                        key, value = param.split("=", 1)
                        params[key.strip()] = value.strip()
                
                chart_result = self.data_tool.create_chart(
                    chart_type=params.get('type', 'bar'),
                    x_col=params.get('x'),
                    y_col=params.get('y'),
                    title=params.get('title')
                )
                result = text[:start] + f"\n\n{chart_result}\n\n" + text[end+1:]
        
        return result
    
    def chat_with_agent(self, user_message: str) -> str:
        """
        Chat with the AI agent
        
        Args:
            user_message: User's message
            
        Returns:
            Agent's response
        """
        try:
            # Build conversation context
            if len(self.history) == 0:
                # First message includes system prompt
                full_message = self._build_system_prompt() + "\n\nNg∆∞·ªùi d√πng: " + user_message
            else:
                # Subsequent messages include conversation history
                context = "\n\n".join([f"Ng∆∞·ªùi d√πng: {h['user']}\nAgent: {h['agent']}" for h in self.history[-3:]])
                full_message = context + "\n\nNg∆∞·ªùi d√πng: " + user_message
            
            # Get response from Gemini
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=full_message
            )
            agent_response = response.text
            
            # Parse and execute commands
            final_response = self._parse_and_execute_commands(agent_response)
            
            # Save to history
            self.history.append({
                'user': user_message,
                'agent': final_response
            })
            
            return final_response
            
        except Exception as e:
            return f"‚ùå L·ªói: {str(e)}"
    
    def change_search_engine(self, engine: str):
        """Change search engine (duckduckgo or serpapi)"""
        if engine.lower() in ['duckduckgo', 'serpapi']:
            Config.SEARCH_ENGINE = engine.lower()
            print(f"‚úì ƒê√£ chuy·ªÉn sang c√¥ng c·ª• t√¨m ki·∫øm: {Config.get_search_engine_display()}")
        else:
            print("‚úó C√¥ng c·ª• t√¨m ki·∫øm kh√¥ng h·ª£p l·ªá. Ch·ªçn 'duckduckgo' ho·∫∑c 'serpapi'.")
    
    def interactive_mode(self):
        """Run agent in interactive mode"""
        print("="*60)
        print("ü§ñ AI AGENT - Interactive Mode")
        print("="*60)
        print("\nL·ªánh ƒë·∫∑c bi·ªát:")
        print("  /search <engine> - ƒê·ªïi c√¥ng c·ª• t√¨m ki·∫øm (duckduckgo/serpapi)")
        print("  /clear - X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i")
        print("  /exit ho·∫∑c /quit - Tho√°t")
        print("\nV√≠ d·ª•:")
        print("  - T√¨m ki·∫øm th√¥ng tin v·ªÅ Python")
        print("  - T√≠nh t√≠ch ph√¢n c·ªßa x^2 t·ª´ 0 ƒë·∫øn 10")
        print("  - Ph√¢n t√≠ch file data.csv c·ªßa t√¥i")
        print("="*60)
        print()
        
        while True:
            try:
                user_input = input("üë§ B·∫°n: ").strip()
                
                if not user_input:
                    continue
                
                # Handle special commands
                if user_input.startswith("/"):
                    cmd = user_input.lower()
                    
                    if cmd in ["/exit", "/quit"]:
                        print("\nüëã T·∫°m bi·ªát!")
                        break
                    
                    elif cmd == "/clear":
                        self.start_conversation()
                        print("‚úì ƒê√£ x√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i")
                        continue
                    
                    elif cmd.startswith("/search "):
                        engine = cmd.split(" ", 1)[1]
                        self.change_search_engine(engine)
                        continue
                    
                    else:
                        print("‚ùå L·ªánh kh√¥ng h·ª£p l·ªá")
                        continue
                
                # Get agent response
                print("\nü§ñ Agent: ", end="", flush=True)
                response = self.chat_with_agent(user_input)
                print(response)
                print()
                
            except KeyboardInterrupt:
                print("\n\nüëã T·∫°m bi·ªát!")
                break
            except Exception as e:
                print(f"\n‚ùå L·ªói: {str(e)}\n")


def main():
    """Main function"""
    agent = AIAgent()
    agent.interactive_mode()


if __name__ == "__main__":
    main()
